{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from transformer_model.layer.multi_head_attention_layer import MultiHeadAttentionLayer\n",
    "from transformer_model.layer.position_wise_feed_forward_layer import PositionWiseFeedForwardLayer\n",
    "from transformer_model.layer.residual_connection_layer import ResidualConnectionLayer\n",
    "\n",
    "from transformer_model.positional_encoding.positional_encoding import PositionalEncoding\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, self_attention, position_ff, norm, dr_rate=0):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
    "        self.position_ff = position_ff\n",
    "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        out = src\n",
    "        out = self.residual1(out, lambda out: self.self_attention(query=out, key=out, value=out, mask=src_mask))\n",
    "        out = self.residual2(out, self.position_ff)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, self_attention, cross_attention, position_ff, norm, dr_rate=0):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attention = self_attention\n",
    "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
    "        self.cross_attention = cross_attention\n",
    "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
    "        self.position_ff = position_ff\n",
    "        self.residual3 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
    "\n",
    "\n",
    "    def forward(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
    "        out = tgt\n",
    "        out = self.residual1(out, lambda out: self.self_attention(query=out, key=out, value=out, mask=tgt_mask))\n",
    "        out = self.residual2(out, lambda out: self.cross_attention(query=out, key=encoder_out, value=encoder_out, mask=src_tgt_mask))\n",
    "        out = self.residual3(out, self.position_ff)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_block, n_layer, norm):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_block) for _ in range(self.n_layer)])\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        out = src\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, src_mask)\n",
    "        out = self.norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_block, n_layer, norm):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(decoder_block) for _ in range(self.n_layer)])\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def forward(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
    "        out = tgt\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, encoder_out, tgt_mask, src_tgt_mask)\n",
    "        out = self.norm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, src_embed, tgt_embed, encoder, decoder, generator):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.generator = generator\n",
    "\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "\n",
    "    def decode(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), encoder_out, tgt_mask, src_tgt_mask)\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        src_tgt_mask = self.make_src_tgt_mask(src, tgt)\n",
    "        encoder_out = self.encode(src, src_mask)\n",
    "        decoder_out = self.decode(tgt, encoder_out, tgt_mask, src_tgt_mask)\n",
    "        out = self.generator(decoder_out)\n",
    "        out = F.log_softmax(out, dim=-1)\n",
    "        return out, decoder_out\n",
    "\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        pad_mask = self.make_pad_mask(src, src)\n",
    "        return pad_mask\n",
    "\n",
    "\n",
    "    def make_tgt_mask(self, tgt):\n",
    "        pad_mask = self.make_pad_mask(tgt, tgt)\n",
    "        seq_mask = self.make_subsequent_mask(tgt, tgt)\n",
    "        mask = pad_mask & seq_mask\n",
    "        return pad_mask & seq_mask\n",
    "\n",
    "\n",
    "    def make_src_tgt_mask(self, src, tgt):\n",
    "        pad_mask = self.make_pad_mask(tgt, src)\n",
    "        return pad_mask\n",
    "\n",
    "\n",
    "    def make_pad_mask(self, query, key, pad_idx=1):\n",
    "        # query: (n_batch, query_seq_len)\n",
    "        # key: (n_batch, key_seq_len)\n",
    "        query_seq_len, key_seq_len = query.size(1), key.size(1)\n",
    "\n",
    "        key_mask = key.ne(pad_idx).unsqueeze(1).unsqueeze(2)  # (n_batch, 1, 1, key_seq_len)\n",
    "        key_mask = key_mask.repeat(1, 1, query_seq_len, 1)    # (n_batch, 1, query_seq_len, key_seq_len)\n",
    "\n",
    "        query_mask = query.ne(pad_idx).unsqueeze(1).unsqueeze(3)  # (n_batch, 1, query_seq_len, 1)\n",
    "        query_mask = query_mask.repeat(1, 1, 1, key_seq_len)  # (n_batch, 1, query_seq_len, key_seq_len)\n",
    "\n",
    "        mask = key_mask & query_mask\n",
    "        mask.requires_grad = False\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def make_subsequent_mask(self, query, key):\n",
    "        query_seq_len, key_seq_len = query.size(1), key.size(1)\n",
    "\n",
    "        tril = np.tril(np.ones((query_seq_len, key_seq_len)), k=0).astype('uint8') # lower triangle without diagonal\n",
    "        mask = torch.tensor(tril, dtype=torch.bool, requires_grad=False, device=query.device)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, pos_embed, dr_rate=0):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.embedding = nn.Sequential(pos_embed)\n",
    "        self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.embedding(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(src_vocab_size,\n",
    "                tgt_vocab_size,\n",
    "                device=torch.device('cuda:0'),\n",
    "                max_len = 256,\n",
    "                d_embed = 512,\n",
    "                n_layer = 6,\n",
    "                d_model = 512,\n",
    "                h = 8,\n",
    "                d_ff = 2048,\n",
    "                dr_rate = 0.1,\n",
    "                norm_eps = 1e-5):\n",
    "    import copy\n",
    "    copy = copy.deepcopy\n",
    "\n",
    "    # src_token_embed = TokenEmbedding(\n",
    "    #                                  d_embed = d_embed,\n",
    "    #                                  vocab_size = src_vocab_size)\n",
    "    # tgt_token_embed = TokenEmbedding(\n",
    "    #                                  d_embed = d_embed,\n",
    "    #                                  vocab_size = tgt_vocab_size)\n",
    "    pos_embed = PositionalEncoding(\n",
    "                                   d_embed = d_embed,\n",
    "                                   max_len = max_len,\n",
    "                                   device = device)\n",
    "\n",
    "    src_embed = TransformerEmbedding(\n",
    "                                     pos_embed = copy(pos_embed),\n",
    "                                     dr_rate = dr_rate)\n",
    "    tgt_embed = TransformerEmbedding(\n",
    "                                     pos_embed = copy(pos_embed),\n",
    "                                     dr_rate = dr_rate)\n",
    "\n",
    "    attention = MultiHeadAttentionLayer(\n",
    "                                        d_model = d_model,\n",
    "                                        h = h,\n",
    "                                        qkv_fc = nn.Linear(d_embed, d_model),\n",
    "                                        out_fc = nn.Linear(d_model, d_embed),\n",
    "                                        dr_rate = dr_rate)\n",
    "    position_ff = PositionWiseFeedForwardLayer(\n",
    "                                               fc1 = nn.Linear(d_embed, d_ff),\n",
    "                                               fc2 = nn.Linear(d_ff, d_embed),\n",
    "                                               dr_rate = dr_rate)\n",
    "    norm = nn.LayerNorm(d_embed, eps = norm_eps)\n",
    "\n",
    "    encoder_block = EncoderBlock(\n",
    "                                 self_attention = copy(attention),\n",
    "                                 position_ff = copy(position_ff),\n",
    "                                 norm = copy(norm),\n",
    "                                 dr_rate = dr_rate)\n",
    "    decoder_block = DecoderBlock(\n",
    "                                 self_attention = copy(attention),\n",
    "                                 cross_attention = copy(attention),\n",
    "                                 position_ff = copy(position_ff),\n",
    "                                 norm = copy(norm),\n",
    "                                 dr_rate = dr_rate)\n",
    "\n",
    "    encoder = Encoder(\n",
    "                      encoder_block = encoder_block,\n",
    "                      n_layer = n_layer,\n",
    "                      norm = copy(norm))\n",
    "    decoder = Decoder(\n",
    "                      decoder_block = decoder_block,\n",
    "                      n_layer = n_layer,\n",
    "                      norm = copy(norm))\n",
    "    generator = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    model = Transformer(\n",
    "                        src_embed = src_embed,\n",
    "                        tgt_embed = tgt_embed,\n",
    "                        encoder = encoder,\n",
    "                        decoder = decoder,\n",
    "                        generator = generator).to(device)\n",
    "    model.device = device\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 (V 시퀀스 / I 시퀀스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('DST_80.csv')\n",
    "# data_I = data.iloc[1919:, 6:7].values\n",
    "# data_V = data.iloc[1919:, 7:8].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_I.shape\n",
    "# data_V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path, x_size):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        self.x = df.iloc[x_size:, 6:10].values\n",
    "        #self.x = np.reshape(x, (x.shape[0], 1, x.shape[1]))\n",
    "\n",
    "        self.y = df.iloc[x_size:, 13:14].values\n",
    "        \n",
    "        self.length = len(df) - x_size\n",
    "\n",
    "    #getitem이거 왜씀?\n",
    "    def __getitem__(self, index):\n",
    "        # x = torch.FloatTensor([self.x[index]])\n",
    "        # y = torch.FloatTensor([self.y[index]])\n",
    "        # return x, y\n",
    "        feature = torch.FloatTensor([self.x[index]])\n",
    "        label = torch.FloatTensor(self.y[index])\n",
    "\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d = CustomDataset(\"DST_80.csv\", 1919) #1919\n",
    "dataset_f = CustomDataset(\"FUDS_80.csv\", 2586) #2586\n",
    "dataset_u = CustomDataset(\"US06_80.csv\", 1207) #1207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.ConcatDataset([dataset_d, dataset_f, dataset_u]) #x,y 어떻게된지 모름\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [len(dataset_d)+len(dataset_f), len(dataset_u)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False, drop_last=False)\n",
    "#validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for idx, (src, tgt) in enumerate(data_loader):\n",
    "        src = src.to(model.device)\n",
    "        tgt = tgt.to(model.device)\n",
    "        tgt_x = tgt[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, _ = model(src, tgt_x)\n",
    "\n",
    "        y_hat = output.contiguous().view(-1, output.shape[-1])\n",
    "        y_gt = tgt_y.contiguous().view(-1)\n",
    "        loss = criterion(y_hat, y_gt)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    num_samples = idx + 1\n",
    "\n",
    "\n",
    "    return epoch_loss / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11980\\1241854177.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  feature = torch.FloatTensor([self.x[index]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, verbose=True, factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     train(model, train_dataloader, optimizer, criterion, \u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m tgt_y \u001b[39m=\u001b[39m tgt[:, \u001b[39m1\u001b[39m:]\n\u001b[0;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m output, _ \u001b[39m=\u001b[39m model(src, tgt_x)\n\u001b[0;32m     15\u001b[0m y_hat \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m     16\u001b[0m y_gt \u001b[39m=\u001b[39m tgt_y\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, tgt):\n\u001b[1;32m---> 21\u001b[0m     src_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_src_mask(src)\n\u001b[0;32m     22\u001b[0m     tgt_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_tgt_mask(tgt)\n\u001b[0;32m     23\u001b[0m     src_tgt_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_src_tgt_mask(src, tgt)\n",
      "Cell \u001b[1;32mIn[6], line 32\u001b[0m, in \u001b[0;36mTransformer.make_src_mask\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_src_mask\u001b[39m(\u001b[39mself\u001b[39m, src):\n\u001b[1;32m---> 32\u001b[0m     pad_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_pad_mask(src, src)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_mask\n",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m, in \u001b[0;36mTransformer.make_pad_mask\u001b[1;34m(self, query, key, pad_idx)\u001b[0m\n\u001b[0;32m     51\u001b[0m query_seq_len, key_seq_len \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), key\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[0;32m     53\u001b[0m key_mask \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mne(pad_idx)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)  \u001b[39m# (n_batch, 1, 1, key_seq_len)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m key_mask \u001b[39m=\u001b[39m key_mask\u001b[39m.\u001b[39;49mrepeat(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, query_seq_len, \u001b[39m1\u001b[39;49m)    \u001b[39m# (n_batch, 1, query_seq_len, key_seq_len)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m query_mask \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mne(pad_idx)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m3\u001b[39m)  \u001b[39m# (n_batch, 1, query_seq_len, 1)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m query_mask \u001b[39m=\u001b[39m query_mask\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, key_seq_len)  \u001b[39m# (n_batch, 1, query_seq_len, key_seq_len)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "model = build_model(16, 4)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, verbose=True, factor=SCHEDULER_FACTOR, patience=SCHEDULER_PATIENCE)\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    train(model, train_dataloader, optimizer, criterion, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
